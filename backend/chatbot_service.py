"""
SIPORTS v2.0 AI Chatbot Service
Service pour chatbot IA gratuit avec support Ollama et simulation pour dÃ©veloppement
"""

import time
import random
import logging
from typing import Dict, List, Optional, Any
from pydantic import BaseModel, Field
from enum import Enum

logger = logging.getLogger(__name__)

class ContextType(str, Enum):
    GENERAL = "general"
    EXHIBITOR = "exhibitor" 
    PACKAGE = "package"
    EVENT = "event"

class ChatRequest(BaseModel):
    message: str = Field(..., min_length=1, max_length=1000, description="Message utilisateur sur Ã©vÃ©nements maritimes")
    context_type: ContextType = Field(default=ContextType.GENERAL, description="Type de contexte pour le chatbot")
    user_id: Optional[str] = Field(default=None, description="Identifiant utilisateur pour suivi session")
    session_id: Optional[str] = Field(default=None, description="ID de session de conversation")

class ChatResponse(BaseModel):
    response: str = Field(..., description="RÃ©ponse IA gÃ©nÃ©rÃ©e")
    response_type: str = Field(..., description="Type de rÃ©ponse fournie")
    confidence: Optional[float] = Field(default=None, description="Score de confiance de la rÃ©ponse")
    suggested_actions: List[str] = Field(default=[], description="Actions suggÃ©rÃ©es de suivi")
    session_id: str = Field(..., description="ID de session")
    timestamp: float = Field(default_factory=time.time, description="Timestamp de la rÃ©ponse")

class SiportsAIService:
    """Service IA pour SIPORTS v2.0 avec support Ollama et mode simulation"""
    
    def __init__(self, mock_mode: bool = True, model_name: str = "tinyllama:1.1b"):
        self.mock_mode = mock_mode
        self.model_name = model_name
        self.conversation_history: Dict[str, List[Dict[str, str]]] = {}
        
        # Templates de contexte pour rÃ©ponses spÃ©cialisÃ©es
        self.context_templates = {
            ContextType.GENERAL: """Tu es un assistant expert pour SIPORTS v2.0, spÃ©cialisÃ© dans les Ã©vÃ©nements maritimes. 
            Fournis des informations prÃ©cises sur les Ã©vÃ©nements maritimes, les horaires, et l'assistance gÃ©nÃ©rale.
            RÃ©pond en franÃ§ais de maniÃ¨re professionnelle et concise.""",
            
            ContextType.EXHIBITOR: """Tu es un conseiller expert en Ã©vÃ©nements maritimes. 
            Aide les utilisateurs Ã  trouver des exposants et fournisseurs pertinents selon leurs intÃ©rÃªts.
            Focus sur les technologies maritimes, shipping, logistics, Ã©quipements navals.
            RÃ©pond en franÃ§ais avec des recommandations prÃ©cises.""",
            
            ContextType.PACKAGE: """Tu es un consultant expert en forfaits Ã©vÃ©nements maritimes. 
            Recommande les forfaits appropriÃ©s: Free (gratuit), Basic (150â‚¬), Premium (350â‚¬), VIP (750â‚¬).
            Explique les avantages de chaque forfait selon les besoins. RÃ©pond en franÃ§ais.""",
            
            ContextType.EVENT: """Tu es un spÃ©cialiste des informations Ã©vÃ©nements maritimes. 
            Fournis des dÃ©tails sur les Ã©vÃ©nements spÃ©cifiques, planning, activitÃ©s, confÃ©rences.
            RÃ©pond en franÃ§ais avec des informations pratiques et utiles."""
        }
        
        # Base de connaissances SIPORTS pour rÃ©ponses contextuelles
        self.siports_knowledge = {
            "forfaits": {
                "Free": {"prix": "Gratuit", "rdv_b2b": 0, "avantages": ["AccÃ¨s exposition", "ConfÃ©rences publiques", "App mobile"]},
                "Basic": {"prix": "150â‚¬", "rdv_b2b": 2, "avantages": ["Expositions", "ConfÃ©rences", "2 RDV B2B", "Pause cafÃ©"]},
                "Premium": {"prix": "350â‚¬", "rdv_b2b": 5, "avantages": ["Ateliers spÃ©cialisÃ©s", "DÃ©jeuners", "5 RDV B2B", "AccÃ¨s VIP"]},
                "VIP": {"prix": "750â‚¬", "rdv_b2b": "illimitÃ©", "avantages": ["SoirÃ©e gala", "ConfÃ©rences exclusives", "Conciergerie", "Transferts"]}
            },
            "exposants_types": [
                "Technologies maritimes", "Ã‰quipements navals", "Logistics et supply chain", 
                "Green shipping", "Smart ports", "CybersÃ©curitÃ© maritime", "Fintech maritime"
            ],
            "Ã©vÃ©nements": [
                "ConfÃ©rences techniques", "Ateliers innovation", "Sessions networking", 
                "DÃ©mos technologiques", "Tables rondes", "SoirÃ©es de gala"
            ]
        }

    def get_session_id(self, user_id: str = None) -> str:
        """GÃ©nÃ¨re ou rÃ©cupÃ¨re un ID de session"""
        if user_id:
            return f"session_{user_id}_{int(time.time())}"
        return f"session_anonymous_{int(time.time())}"

    async def generate_response_mock(self, message: str, context_type: ContextType, session_id: str) -> str:
        """GÃ©nÃ¨re une rÃ©ponse simulÃ©e intelligente basÃ©e sur le contexte"""
        
        message_lower = message.lower()
        
        # RÃ©ponses contextuelles basÃ©es sur le type
        if context_type == ContextType.PACKAGE:
            if any(word in message_lower for word in ["forfait", "package", "prix", "tarif"]):
                return self._generate_package_response(message_lower)
        
        elif context_type == ContextType.EXHIBITOR:
            if any(word in message_lower for word in ["exposant", "entreprise", "technologie", "fournisseur"]):
                return self._generate_exhibitor_response(message_lower)
        
        elif context_type == ContextType.EVENT:
            if any(word in message_lower for word in ["Ã©vÃ©nement", "confÃ©rence", "horaire", "programme"]):
                return self._generate_event_response(message_lower)
        
        # RÃ©ponse gÃ©nÃ©rale par dÃ©faut
        return self._generate_general_response(message_lower)

    def _generate_package_response(self, message: str) -> str:
        """GÃ©nÃ¨re rÃ©ponse sur les forfaits"""
        if "gratuit" in message or "free" in message:
            return "Le forfait Free est gratuit et inclut l'accÃ¨s Ã  l'exposition, aux confÃ©rences publiques et Ã  l'app mobile. IdÃ©al pour dÃ©couvrir l'Ã©vÃ©nement."
        
        if "premium" in message or "vip" in message:
            return "Le forfait Premium (350â‚¬) est notre plus populaire avec 5 RDV B2B, ateliers spÃ©cialisÃ©s, dÃ©jeuners networking et accÃ¨s VIP. Le VIP (750â‚¬) offre RDV illimitÃ©s, soirÃ©e gala et service conciergerie."
        
        if "basic" in message:
            return "Le forfait Basic (150â‚¬) comprend l'accÃ¨s expositions, confÃ©rences principales, 2 RDV B2B garantis et pauses cafÃ© networking. Parfait pour 1 jour d'Ã©vÃ©nement."
        
        return "Nous proposons 4 forfaits: Free (gratuit), Basic (150â‚¬), Premium (350â‚¬) et VIP (750â‚¬). Chacun offre des avantages diffÃ©rents selon vos besoins. Que recherchez-vous prÃ©cisÃ©ment?"

    def _generate_exhibitor_response(self, message: str) -> str:
        """GÃ©nÃ¨re rÃ©ponse sur les exposants"""
        if any(word in message for word in ["technologie", "tech", "innovation"]):
            return "Nos exposants technologiques incluent des leaders en smart ports, IoT maritime, blockchain pour logistics, et solutions d'automatisation portuaire. Souhaitez-vous des recommandations spÃ©cifiques?"
        
        if any(word in message for word in ["shipping", "transport", "logistique"]):
            return "Pour le shipping et logistique, nous avons des exposants spÃ©cialisÃ©s en supply chain maritime, optimisation de routes, tracking cargo, et solutions green shipping. Je peux vous orienter selon votre secteur."
        
        if any(word in message for word in ["Ã©quipement", "naval", "bateau"]):
            return "Les Ã©quipementiers navals prÃ©sents proposent systÃ¨mes de navigation, Ã©quipements de sÃ©curitÃ©, solutions de maintenance prÃ©dictive et technologies offshore. Quel type d'Ã©quipement vous intÃ©resse?"
        
        return "Nos 200+ exposants couvrent toute la chaÃ®ne maritime: technologies, Ã©quipements, services, financement. Pouvez-vous prÃ©ciser votre domaine d'intÃ©rÃªt pour des recommandations ciblÃ©es?"

    def _generate_event_response(self, message: str) -> str:
        """GÃ©nÃ¨re rÃ©ponse sur les Ã©vÃ©nements"""
        if any(word in message for word in ["horaire", "programme", "planning"]):
            return "L'Ã©vÃ©nement se dÃ©roule sur 3 jours avec confÃ©rences (9h-17h), ateliers techniques (14h-16h), sessions networking (17h-19h) et soirÃ©e gala (20h). Voulez-vous le programme dÃ©taillÃ© d'une journÃ©e?"
        
        if any(word in message for word in ["confÃ©rence", "prÃ©sentation", "speaker"]):
            return "Nous avons 50+ confÃ©rences couvrant dÃ©carbonation maritime, digitalisation des ports, nouvelles rÃ©glementations et innovations technologiques. Les speakers incluent des experts internationaux. Quel thÃ¨me vous intÃ©resse?"
        
        if "networking" in message or "rencontre" in message:
            return "Les opportunitÃ©s networking incluent: pauses cafÃ© (10h et 15h), dÃ©jeuners thÃ©matiques (12h), cocktail exposants (17h) et soirÃ©e gala (20h). IdÃ©al pour crÃ©er des connexions professionnelles."
        
        return "L'Ã©vÃ©nement SIPORTS propose confÃ©rences, ateliers, networking et expo sur 3 jours. Programme complet avec 200+ exposants et 50+ confÃ©rences. Que souhaitez-vous savoir spÃ©cifiquement?"

    def _generate_general_response(self, message: str) -> str:
        """GÃ©nÃ¨re rÃ©ponse gÃ©nÃ©rale"""
        greetings = ["bonjour", "hello", "salut", "bonsoir"]
        if any(greeting in message for greeting in greetings):
            return "Bonjour ! Je suis l'assistant IA SIPORTS v2.0. Je peux vous aider avec les informations Ã©vÃ©nements, recommandations exposants, forfaits et planning. Comment puis-je vous assister ?"
        
        if any(word in message for word in ["aide", "help", "assistance"]):
            return "Je peux vous assister sur: ðŸ“‹ Informations Ã©vÃ©nements, ðŸ¢ Recommandations exposants, ðŸ’³ Forfaits et tarifs, ðŸ“… Programme et horaires. Sur quoi souhaitez-vous Ãªtre accompagnÃ© ?"
        
        if "siports" in message or "Ã©vÃ©nement" in message:
            return "SIPORTS est le salon maritime de rÃ©fÃ©rence avec 200+ exposants, 50+ confÃ©rences et 3 jours d'innovations. Technologies, networking, business opportunities vous attendent. Que voulez-vous dÃ©couvrir ?"
        
        return "Je suis lÃ  pour vous aider avec toutes vos questions sur SIPORTS v2.0. Ã‰vÃ©nements, exposants, forfaits, planning - n'hÃ©sitez pas Ã  me demander ! ðŸ˜Š"

    def _generate_suggested_actions(self, context_type: ContextType, message: str) -> List[str]:
        """GÃ©nÃ¨re actions suggÃ©rÃ©es selon le contexte"""
        actions_map = {
            ContextType.GENERAL: ["ðŸ“‹ Voir programme Ã©vÃ©nement", "ðŸ¢ Parcourir exposants", "ðŸ’³ DÃ©couvrir forfaits", "ðŸ“ž Contact support"],
            ContextType.EXHIBITOR: ["ðŸ” Voir dÃ©tails exposant", "ðŸ“… Planifier rendez-vous", "ðŸ“§ Obtenir contact", "ðŸ”— Voir partenariats"],
            ContextType.PACKAGE: ["âš–ï¸ Comparer forfaits", "ðŸ’° Voir tarifs", "ðŸŽŸï¸ S'inscrire maintenant", "ðŸ“ž Devis personnalisÃ©"],
            ContextType.EVENT: ["ðŸ“… Ajouter au calendrier", "â° DÃ©finir rappels", "ðŸ“¤ Partager Ã©vÃ©nement", "ðŸŽ« RÃ©server place"]
        }
        return actions_map.get(context_type, [])

    async def generate_response(self, request: ChatRequest) -> ChatResponse:
        """Point d'entrÃ©e principal pour gÃ©nÃ©ration de rÃ©ponse"""
        try:
            session_id = request.session_id or self.get_session_id(request.user_id)
            
            # Gestion historique conversation
            if session_id not in self.conversation_history:
                self.conversation_history[session_id] = []
            
            # Ajouter message utilisateur Ã  l'historique
            self.conversation_history[session_id].append({
                "role": "user",
                "content": request.message,
                "timestamp": time.time()
            })
            
            # Limiter historique Ã  20 derniers Ã©changes
            if len(self.conversation_history[session_id]) > 20:
                self.conversation_history[session_id] = self.conversation_history[session_id][-20:]

            if self.mock_mode:
                # Mode simulation pour dÃ©veloppement
                ai_response = await self.generate_response_mock(request.message, request.context_type, session_id)
                confidence = round(random.uniform(0.8, 0.95), 2)
            else:
                # Mode Ollama (Ã  implÃ©menter en production)
                ai_response = await self.generate_response_ollama(request, session_id)
                confidence = 0.85

            # Ajouter rÃ©ponse IA Ã  l'historique
            self.conversation_history[session_id].append({
                "role": "assistant", 
                "content": ai_response,
                "timestamp": time.time()
            })
            
            # GÃ©nÃ©rer actions suggÃ©rÃ©es
            suggested_actions = self._generate_suggested_actions(request.context_type, request.message)
            
            return ChatResponse(
                response=ai_response,
                response_type=request.context_type.value if hasattr(request.context_type, 'value') else request.context_type,
                confidence=confidence,
                suggested_actions=suggested_actions,
                session_id=session_id
            )
            
        except Exception as e:
            logger.error(f"Erreur gÃ©nÃ©ration rÃ©ponse chatbot: {str(e)}")
            return ChatResponse(
                response="DÃ©solÃ©, je rencontre une difficultÃ© technique. Pouvez-vous reformuler votre question ?",
                response_type=request.context_type.value if hasattr(request.context_type, 'value') else request.context_type,
                confidence=0.0,
                suggested_actions=["ðŸ”„ RÃ©essayer", "ðŸ“ž Contact support"],
                session_id=session_id or "error_session"
            )

    async def generate_response_ollama(self, request: ChatRequest, session_id: str) -> str:
        """GÃ©nÃ©ration rÃ©ponse avec Ollama (implÃ©mentation future)"""
        # TODO: ImplÃ©menter l'intÃ©gration Ollama rÃ©elle
        try:
            import ollama
            
            # PrÃ©parer le contexte systÃ¨me
            system_prompt = self.context_templates[request.context_type]
            
            # PrÃ©parer l'historique pour le contexte
            messages = [{"role": "system", "content": system_prompt}]
            
            # Ajouter historique rÃ©cent (5 derniers Ã©changes)
            recent_history = self.conversation_history[session_id][-10:] if session_id in self.conversation_history else []
            for msg in recent_history:
                messages.append({"role": msg["role"], "content": msg["content"]})
            
            # GÃ©nÃ©rer rÃ©ponse avec Ollama
            response = ollama.chat(
                model=self.model_name,
                messages=messages,
                options={
                    "temperature": 0.7,
                    "max_tokens": 500,
                    "top_p": 0.9
                }
            )
            
            return response['message']['content']
            
        except ImportError:
            logger.warning("Ollama non disponible, utilisation du mode mock")
            return await self.generate_response_mock(request.message, request.context_type, session_id)
        except Exception as e:
            logger.error(f"Erreur Ollama: {str(e)}")
            return await self.generate_response_mock(request.message, request.context_type, session_id)

    def get_conversation_history(self, session_id: str) -> List[Dict[str, Any]]:
        """RÃ©cupÃ¨re l'historique de conversation pour une session"""
        return self.conversation_history.get(session_id, [])

    def clear_conversation_history(self, session_id: str) -> bool:
        """Efface l'historique d'une session"""
        if session_id in self.conversation_history:
            del self.conversation_history[session_id]
            return True
        return False

# Instance globale du service chatbot
siports_ai_service = SiportsAIService(mock_mode=True)